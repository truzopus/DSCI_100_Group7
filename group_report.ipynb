{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook: Paid vs Unpaid Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "Background: \n",
    "    We are in the digital era, and Facebook is one of the biggest social media platforms known to society. Hence, it is a great place for businesses to reach consumers globally. With this idea in mind, we believe it would be beneficial for businesses to know if they should pay for a post to achieve a certain number of post total reach, post engagements, and page likes, or if it is better to follow the organic route. This is significant for designing marketing strategies, especially for small businesses or start-ups with small funds. We chose two different metrics for Facebook posts that we thought would have the highest influence on the success of advertising, lifetime post total reach and lifetime people who have liked the page and engaged with the post, to make a prediction on whether the post was paid or unpaid.\n",
    "\n",
    "Question: \n",
    "    **Can we use the amount of lifetime post total reach and lifetime people who have liked the page and engaged with the post to predict whether a future post is paid or unpaid?**\n",
    "\n",
    "Dataset: \n",
    "    The [dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/00368/Facebook_metrics.zip) we have is from 790Facebook posts of a renowned cosmetic brand in 2014, and it shows the type of post (paid vs unpaid) as well as information on it, from the number of likes and shares to total impressions. According to the paper from which the dataset is based on, \"Most of the information was exported directly from the company's Facebook page\", and this includes \"paid\", \"lifetime post total reach\", and \"lifetime people who have liked the page and engaged with the post\", the columns that we are interested in. The link to the dataset is: https://archive.ics.uci.edu/ml/machine-learning-databases/00368/Facebook_metrics.zip \n",
    "\n",
    "Predictor variable description: \n",
    "\n",
    "   \"Lifetime post total reach\" is a chosen predictor because it is a measure of how much exposure a post achieves by the quantifying the number of unique users who have seen the post in their screen. In this scenario, \"unique users\" mean that an individual who owns multiple accounts is only considered as one user. \n",
    "\n",
    "   On the other hand, \"lifetime people who have liked the page and engaged with the post\" is the number of unique users who have liked the page and clicked anywhere in a page's post. \"Engagements\" pertain to all the types and origins of clicks on the specific post. This predictor is chosen as it is said to be a stronger measure for user feedback, since this would ensure that the user is interested in the post. Therefore, we use these two predictors to determine if the post was organic or not because we believe companies would want to know whether their post is both seen and engaged with. (http://www.math-evry.cnrs.fr/_media/members/aguilloux/enseignements/m1mint/moro2016.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1\n",
    "The following packages are loaded using the `library` function to be able to use the functions necessary to build, tune, and estimate the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.3     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "Warning message:\n",
      "“package ‘ggplot2’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘tibble’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘tidyr’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 4.0.2”\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Warning message:\n",
      "“package ‘tidymodels’ was built under R version 4.0.2”\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 0.1.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom    \u001b[39m 0.7.0      \u001b[32m✔\u001b[39m \u001b[34mrecipes  \u001b[39m 0.1.13\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials    \u001b[39m 0.0.9      \u001b[32m✔\u001b[39m \u001b[34mrsample  \u001b[39m 0.0.7 \n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer    \u001b[39m 0.5.4      \u001b[32m✔\u001b[39m \u001b[34mtune     \u001b[39m 0.1.1 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata\u001b[39m 0.0.2      \u001b[32m✔\u001b[39m \u001b[34mworkflows\u001b[39m 0.2.0 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip  \u001b[39m 0.1.3      \u001b[32m✔\u001b[39m \u001b[34myardstick\u001b[39m 0.0.7 \n",
      "\n",
      "Warning message:\n",
      "“package ‘broom’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘dials’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘infer’ was built under R version 4.0.3”\n",
      "Warning message:\n",
      "“package ‘modeldata’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘parsnip’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘recipes’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘tune’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘workflows’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘yardstick’ was built under R version 4.0.2”\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "library(repr)\n",
    "library(tidyverse)\n",
    "library(tidymodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2\n",
    "The dataset can be downloaded from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Facebook+metrics). The as_factor() function is used to convert the Paid column into a factor instead of an integer. With this, it can now be used as a class/label that observations can be categorized into. Moreover, the select() function is used to select the columns, Lifetime Post Total Reach, and Lifetime People who have liked your Page and engaged with your post, as the chosen predictors for our classifier. Furthermore, in this dataset, 0 = unpaid and 1 = paid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 499 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Paid</th><th scope=col>Lifetime_Post</th><th scope=col>Lifetime_Like_Engage</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl[,1]&gt;</th><th scope=col>&lt;dbl[,1]&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>-0.4908219</td><td>-0.8016572</td></tr>\n",
       "\t<tr><td>0</td><td>-0.1521492</td><td> 0.8111968</td></tr>\n",
       "\t<tr><td>0</td><td>-0.5057168</td><td>-0.7804569</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>0</td><td>-0.4588352</td><td>-0.5048529</td></tr>\n",
       "\t<tr><td>0</td><td>-0.4457417</td><td>-0.4037438</td></tr>\n",
       "\t<tr><td>0</td><td>-0.4291332</td><td>-0.3923282</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 499 × 3\n",
       "\\begin{tabular}{lll}\n",
       " Paid & Lifetime\\_Post & Lifetime\\_Like\\_Engage\\\\\n",
       " <fct> & <dbl{[},1{]}> & <dbl{[},1{]}>\\\\\n",
       "\\hline\n",
       "\t 0 & -0.4908219 & -0.8016572\\\\\n",
       "\t 0 & -0.1521492 &  0.8111968\\\\\n",
       "\t 0 & -0.5057168 & -0.7804569\\\\\n",
       "\t ⋮ & ⋮ & ⋮\\\\\n",
       "\t 0 & -0.4588352 & -0.5048529\\\\\n",
       "\t 0 & -0.4457417 & -0.4037438\\\\\n",
       "\t 0 & -0.4291332 & -0.3923282\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 499 × 3\n",
       "\n",
       "| Paid &lt;fct&gt; | Lifetime_Post &lt;dbl[,1]&gt; | Lifetime_Like_Engage &lt;dbl[,1]&gt; |\n",
       "|---|---|---|\n",
       "| 0 | -0.4908219 | -0.8016572 |\n",
       "| 0 | -0.1521492 |  0.8111968 |\n",
       "| 0 | -0.5057168 | -0.7804569 |\n",
       "| ⋮ | ⋮ | ⋮ |\n",
       "| 0 | -0.4588352 | -0.5048529 |\n",
       "| 0 | -0.4457417 | -0.4037438 |\n",
       "| 0 | -0.4291332 | -0.3923282 |\n",
       "\n"
      ],
      "text/plain": [
       "    Paid Lifetime_Post Lifetime_Like_Engage\n",
       "1   0    -0.4908219    -0.8016572          \n",
       "2   0    -0.1521492     0.8111968          \n",
       "3   0    -0.5057168    -0.7804569          \n",
       "⋮   ⋮    ⋮             ⋮                   \n",
       "497 0    -0.4588352    -0.5048529          \n",
       "498 0    -0.4457417    -0.4037438          \n",
       "499 0    -0.4291332    -0.3923282          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(3060) # setting seed to make data analysis reproducible\n",
    "\n",
    "options(repr.plot.width = 8, repr.plot.height = 8)\n",
    "options(repr.matrix.max.rows = 6)\n",
    "\n",
    "# load data\n",
    "temp <- tempfile()\n",
    "download.file(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00368/Facebook_metrics.zip\", temp, mode = \"wb\")\n",
    "unzip(temp, \"dataset_Facebook.csv\")\n",
    "facebook_unscaled <- read.delim(\"dataset_Facebook.csv\", sep = \";\") %>% \n",
    "    mutate(Paid = as_factor(Paid)) %>% \n",
    "    select(Paid, \n",
    "           Lifetime_Post = Lifetime.Post.Total.Reach,\n",
    "           Lifetime_Like_Engage = Lifetime.People.who.have.liked.your.Page.and.engaged.with.your.post\n",
    "          )\n",
    "\n",
    "# scale data\n",
    "facebook <- facebook_unscaled %>%\n",
    "    filter(!is.na(Paid)) %>%\n",
    "    mutate(Lifetime_Post = scale(Lifetime_Post, center = TRUE), Lifetime_Like_Engage = scale(Lifetime_Like_Engage, center = TRUE))\n",
    "facebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 1: Scaled Facebook Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3\n",
    "The dataset is then randomly shuffled and split into a training and testing set, wherein the training set consists of 75% of the data and the testing set consists of the remaining 25%. The training set will be used to build and tune the k-nn classifier, and the testing set will be used to estimate the prediction accuracy of this classifier. We also specify the classifier that the class we want to predict is the Paid column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into a training and testing dataset\n",
    "facebook_split <- initial_split(facebook, prop = 0.75, strata = Paid) \n",
    "facebook_train <- training(facebook_split)   \n",
    "facebook_test <- testing(facebook_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4\n",
    "Using the training dataset, we build and tune the classifier that we will use to predict observations. It is important that we scale and center the chosen predictors, using the setp_scale() and step_center() functions, to ensure that no variable would have a higher influence in the prediction due to their larger scale. We include in our recipe that the predictors we want are Lifetime_Post and Liketime_Like_Engage, therefore using all_predictors() would mean that these are the variables we would like to scale and center. Furthermore, we do 5-fold cross-validation, using the vfold_cv() function, to build the model to establish the number of neighbours that would be best to achieve the highest estimated accuracy. We then add the recipe and model into our workflow wherein we tell the classifier we want to try tuning it with 10 different Ks through the grid argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building and tuning the classifier\n",
    "facebook_recipe <- recipe(Paid ~ Lifetime_Post + Lifetime_Like_Engage, data = facebook_train) %>%\n",
    "   step_scale(all_predictors()) %>%\n",
    "   step_center(all_predictors())\n",
    "\n",
    "facebook_vfold <- vfold_cv(facebook_train, v = 5, strata = Paid)\n",
    "\n",
    "knn_tune<- nearest_neighbor(weight_func = 'rectangular', neighbors = tune()) %>%\n",
    "      set_engine('kknn') %>%\n",
    "      set_mode('classification')\n",
    "\n",
    "knn_results <- workflow() %>%\n",
    "      add_recipe(facebook_recipe) %>%\n",
    "      add_model(knn_tune) %>%\n",
    "      tune_grid(resamples = facebook_vfold, grid = 10) %>%\n",
    "      collect_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5\n",
    "Because we only care about the mean of the accuracy, we use the filter() function to filter out these specific rows under the .metric column. We then plot out the graph wherein the x-axis consists of the neighbors column and the y-axis contains the respective means of these neighbours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing the correct number of neighbours\n",
    "accuracies <- knn_results %>% \n",
    "      filter(.metric == 'accuracy')\n",
    "\n",
    "accuracy_versus_k <- ggplot(accuracies, aes(x = neighbors, y = mean))+\n",
    "      geom_point() +\n",
    "      geom_line() +\n",
    "      labs(x = \"Neighbors\", y = \"Accuracy Estimate\")\n",
    "\n",
    "accuracy_versus_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graph 1: K value vs Accuracy Graph**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6\n",
    "Through the graph, we see that the number of neighbours with the highest accuracy estimate of around 70% is 14. We use the filter() function to filter out the row with the highest mean and pull(neighbors) function to pull the value of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building classifier with chosen number of neighbours\n",
    "k_max <- accuracies %>%\n",
    "    filter(mean == max(mean)) %>%\n",
    "    pull(neighbors)\n",
    "k_max\n",
    "\n",
    "knn_spec <- nearest_neighbor(weight_func = 'rectangular', neighbors = k_max) %>%\n",
    "      set_engine('kknn') %>%\n",
    "      set_mode('classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimating the classifier's validation/prediction accuracy\n",
    "facebook_fit <- workflow() %>%\n",
    "      add_recipe(facebook_recipe) %>%\n",
    "      add_model(knn_spec) %>%\n",
    "      fit_resamples(resamples = facebook_vfold)\n",
    "\n",
    "facebook_metrics<-collect_metrics(facebook_fit)\n",
    "facebook_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 2: Classifier's Prediction Accuracy on the Training Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimating the accuracy of the classifier on the testing data\n",
    "facebook_fit_test <- workflow() %>%\n",
    "    add_recipe(facebook_recipe) %>%\n",
    "    add_model(knn_spec) %>%\n",
    "    fit(data = facebook_train)\n",
    "\n",
    "facebook_test_prediction <- predict(facebook_fit_test, facebook_test) %>%\n",
    "    bind_cols(facebook_test)\n",
    "\n",
    "facebook_metrics <- facebook_test_prediction %>%\n",
    "    metrics(truth = Paid, estimate = .pred_class)\n",
    "facebook_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 3: Classifier's Prediction Accuracy on the Testing Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion <- facebook_test_prediction %>%\n",
    "    conf_mat(truth = Paid, estimate = .pred_class)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 4: Confusion Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of predictor variables relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the scaled variables\n",
    "facebook_plot <- ggplot(facebook, aes(x = Lifetime_Post, y = Lifetime_Like_Engage, colour = Paid)) +\n",
    "    geom_point() +\n",
    "    labs(x = \"Total Reach of Post (Lifetime)\", y = \"Number of People Who Have Liked Page \\n and Engaged with  Post (Lifetime)\",\n",
    "              color = \"Post Type\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "facebook_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graph 2: Lifetime Post Total Reach vs Lifetime People who have Liked the page and Engaged with the post**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it was found that Lifetime Post reach and Lifetime Likes and Engagement are moderately accurate predictors of whether a Facebook post is paid or not. Although the classifiers have a combined accuracy of around 70%, the predicted trend is not reliably seen in our results. Contrary to our hypothesis, a higher lifetime post count and higher lifetime likes + engagement did not reliably correlate to a paid post. This finding seemingly replicates the findings of another study \n",
    "(https://www.sciencedirect.com/science/article/pii/S0148296316000813), where it was found that a paid post only boosts its reachability by 7%. Interestingly, lifetime post reach is a slightly more accurate predictor, compared to the other variable we tested. Another study by (https://www.tandfonline.com/doi/abs/10.1080/10641734.2018.1503113?journalCode=ujci20) found that many different factors may affect post likes and engagement. For example, post content and even when the post was created have significant effects on how many likes/engagements the post achieves. Thus, these other factors should be examined in future studies to determine how they may act as moderating factors. In terms of application, companies can use this information, combined with actual purchasing data, to streamline their advertising strategies.  Specifically, paying for a specific type of post in a specific month may help increase post reach, which would increase potential consumer exposure, which may in turn increase purchases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
